""""
Data based on the data used for:
Pınar Tüfekci, Prediction of full load electrical power output of a base load operated combined cycle power plant using machine learning methods, International Journal of Electrical Power & Energy Systems, Volume 60, September 2014, Pages 126-140, ISSN 0142-0615, http://dx.doi.org/10.1016/j.ijepes.2014.02.027.
(http://www.sciencedirect.com/science/article/pii/S0142061514000908)

Heysem Kaya, Pınar Tüfekci , Sadık Fikret Gürgen: Local and Global Learning Methods for Predicting Power of a Combined Gas & Steam Turbine, Proceedings of the International Conference on Emerging Trends in Computer and Electronics Engineering ICETCEE 2012, pp. 13-18 (Mar. 2012, Dubai)
"""
import logging
import os
import tempfile
import zipfile
from pathlib import Path

import pandas as pd
import psycopg2
import requests
from logger import get_logger

logger = get_logger(Path(__file__).stem)
TABLE_NAME = "powerplant"


def download_file(url: str, local_file_path: Path) -> Path:
    with requests.get(url, stream=True) as r:
        r.raise_for_status()
        with open(local_file_path, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192):
                # If you have chunk encoded response uncomment if
                # and set chunk_size parameter to None.
                # if chunk:
                f.write(chunk)
    return local_file_path


class PowerPlantDBInitializer:
    def __init__(self, logger: logging.Logger = get_logger("PowerPlantDBInitializer")):
        self.logger = logger
        self.host = os.environ.get("POSTGRES_HOST")
        self.database = os.environ.get("POSTGRES_DB")
        self.user = os.environ.get("POSTGRES_USER")
        self.password = os.environ.get("POSTGRES_PASSWORD")
        self.port = "5432"
        self.table_name = TABLE_NAME
        self.conn = None
        self.generate_connection()
        self.columns = ["AT", "V", "AP", "RH", "PE"]

    def generate_connection(self):
        if self.conn is None:
            self.logger.info("Creating connection to PostgreSQL")
            self.conn = psycopg2.connect(
                host=self.host, database=self.database, user=self.user, password=self.password, port=self.port
            )

    def commit_connection(self):
        if self.conn is not None:
            self.conn.commit()

    def close_connection(self):
        if self.conn is not None:
            self.logger.info("Closing connection to Postgresql")
            self.conn.close()

    def insert_row(self, args_list: list):
        if self.table_exists():
            self.generate_connection()
            query = f"INSERT INTO {self.table_name} ({', '.join(self.columns)}) VALUES ({', '.join(['%s' for _ in self.columns])})"
            cur = self.conn.cursor()
            cur.execute(query, args_list)
            cur.close()
            self.commit_connection()

    def table_exists(self):
        table_existence_command = f"""
        SELECT EXISTS(SELECT 1 FROM information_schema.tables
                        WHERE table_catalog='{self.database}' AND
                        table_schema='public' AND
                        table_name='{self.table_name}');
                        """
        self.generate_connection()
        cur = self.conn.cursor()
        cur.execute(table_existence_command)
        response = cur.fetchall()
        cur.close()
        return response[0][0]

    def create_table(self):
        if not self.table_exists():
            self.logger.info(f"Creating table: {self.table_name}")
            create_command = (
                f"""CREATE TABLE {self.table_name} (id integer PRIMARY KEY generated by default as identity,"""
            )
            dtypes_command = ", ".join([f"{col} NUMERIC NOT NULL" for col in self.columns])
            full_command = create_command + dtypes_command + ")"
            self.generate_connection()
            cur = self.conn.cursor()
            cur.execute(full_command)
            cur.close()
            self.commit_connection()

    def retrieve_all(self):
        if self.table_exists():
            self.generate_connection()
            cur = self.conn.cursor()
            cur.execute(f"SELECT * FROM {self.table_name}")
            response = cur.fetchall()
            cur.close()
        else:
            response = []
        return response

    def count_rows(self):
        if self.table_exists():
            self.generate_connection()
            cur = self.conn.cursor()
            cur.execute(f"SELECT COUNT(*) FROM {self.table_name}")
            response = cur.fetchall()[0][0]
            cur.close()
        else:
            response = 0
        return response

    def delete_table(self):
        self.logger.info(f"Deleting table: {self.table_name}")
        delete_command = f"""DROP TABLE {self.table_name}"""
        self.generate_connection()
        cur = self.conn.cursor()
        cur.execute(delete_command)
        cur.close()
        self.commit_connection()


def create_tables(pplant_data_path):
    df = pd.read_excel(str(pplant_data_path / "CCPP" / "Folds5x2_pp.xlsx"))

    try:
        powerplant_db_initializer = PowerPlantDBInitializer()
        powerplant_db_initializer.create_table()

        if powerplant_db_initializer.count_rows() < 1:
            logger.info(f"Pushing power plant data to PostgreSQL")
            for row in df.iterrows():
                powerplant_db_initializer.insert_row(list(row[1]))
        else:
            logger.warning(
                f"Database already contains {powerplant_db_initializer.count_rows()} rows of data, skipping initialization"
            )

    except (Exception, psycopg2.DatabaseError) as error:
        print(error)
    finally:
        if powerplant_db_initializer.conn is not None:
            powerplant_db_initializer.close_connection()


def main():
    url = "https://archive.ics.uci.edu/static/public/294/combined+cycle+power+plant.zip"
    with tempfile.TemporaryDirectory() as tmp_dir:
        # Download data
        logger.info(f"Downloading data from {url}")
        temp_file = Path(tmp_dir) / "powerplant.zip"
        download_file(url, temp_file)

        # Extract/uncompress it
        logger.info("Uncompressing data")
        pplant_data_path = Path(tmp_dir) / "pplant"
        with zipfile.ZipFile(temp_file, "r") as zip_ref:
            zip_ref.extractall(pplant_data_path)

        # Push to data server
        logger.info("Pushing data to PostgreSQL")
        create_tables(pplant_data_path)
        logger.info("Done")


if __name__ == "__main__":
    main()
